{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257d0f88",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65807945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7933d",
   "metadata": {},
   "source": [
    "# üìå Approach 1: Agglomerative Clustering (Scikit-learn + SciPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01486300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2), (50,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synthetic data\n",
    "X,y = make_blobs(n_samples= 50, centers= 3, cluster_std=1.0, random_state=42)\n",
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3947e",
   "metadata": {},
   "source": [
    "üîç Explanation of Parameters:\n",
    "n_samples=100:\n",
    "We're generating 100 data points in total.\n",
    "\n",
    "centers=3:\n",
    "These 100 data points will be grouped into 3 natural clusters (ground-truth clusters), which the clustering algorithm should ideally find.\n",
    "\n",
    "cluster_std=1.0:\n",
    "This controls how spread out each cluster is. A higher value means more overlap between clusters, making them harder to separate.\n",
    "\n",
    "random_state=42:\n",
    "Ensures that the random generation is consistent every time the code runs (reproducibility).\n",
    "\n",
    "X:\n",
    "This is the actual data ‚Äî a 2D array of shape (100, 2) representing the features (usually 2D for easy visualization).\n",
    "\n",
    "y:\n",
    "These are the ground truth labels (0, 1, 2), which we only use for evaluation or visualization ‚Äî not during clustering itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90aaa22",
   "metadata": {},
   "source": [
    "üß† Same Dataset, Different Approaches:\n",
    "Agglomerative Hierarchical Clustering:\n",
    "Starts by treating each of the 100 points as its own cluster and then merges them step-by-step based on distance until it reaches 3 clusters (or fewer if you don‚Äôt stop it).\n",
    "\n",
    "Divisive Hierarchical Clustering (not directly supported in scikit-learn):\n",
    "Conceptually works in reverse ‚Äî starts with all 100 points in one big cluster and recursively splits it into smaller clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0259f0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3, 10],\n",
       "       [-2,  7],\n",
       "       [ 3,  1],\n",
       "       [-9, -6],\n",
       "       [-3,  7],\n",
       "       [-1,  8],\n",
       "       [-3,  9],\n",
       "       [-2,  7],\n",
       "       [ 5,  2],\n",
       "       [-7, -7],\n",
       "       [ 5,  2],\n",
       "       [ 4,  0],\n",
       "       [ 3,  0],\n",
       "       [-2,  7],\n",
       "       [ 4,  3],\n",
       "       [-1,  7],\n",
       "       [-7, -7],\n",
       "       [-6, -7],\n",
       "       [ 4,  2],\n",
       "       [-4,  8],\n",
       "       [ 4,  2],\n",
       "       [-7, -6],\n",
       "       [-3,  9],\n",
       "       [-6, -6],\n",
       "       [-2,  7],\n",
       "       [-7, -6],\n",
       "       [-3,  9],\n",
       "       [ 3,  1],\n",
       "       [-6, -7],\n",
       "       [ 4,  3],\n",
       "       [-7, -7],\n",
       "       [ 5,  3],\n",
       "       [ 4,  1],\n",
       "       [ 0,  9],\n",
       "       [ 5,  3],\n",
       "       [-7, -6],\n",
       "       [-6, -5],\n",
       "       [ 4,  1],\n",
       "       [ 4,  1],\n",
       "       [-8, -7],\n",
       "       [-7, -8],\n",
       "       [-3,  9],\n",
       "       [-6, -8],\n",
       "       [-2,  8],\n",
       "       [-2,  9],\n",
       "       [-5, -7],\n",
       "       [-3,  8],\n",
       "       [-5, -6],\n",
       "       [ 3,  2],\n",
       "       [ 5,  1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.astype(int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f59392ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create linkage matrix for dendrogram\n",
    "linked = linkage(X, method='ward')\n",
    "linked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a407457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 22,  0,  2],\n",
       "       [26, 50,  0,  3],\n",
       "       [41, 51,  0,  4],\n",
       "       [ 1,  7,  0,  2],\n",
       "       [ 2, 27,  0,  2],\n",
       "       [ 9, 16,  0,  2],\n",
       "       [30, 55,  0,  3],\n",
       "       [21, 25,  0,  2],\n",
       "       [35, 57,  0,  3],\n",
       "       [17, 28,  0,  2],\n",
       "       [13, 53,  0,  3],\n",
       "       [24, 60,  0,  4],\n",
       "       [ 8, 10,  0,  2],\n",
       "       [18, 20,  0,  2],\n",
       "       [31, 34,  0,  2],\n",
       "       [32, 37,  0,  2],\n",
       "       [38, 65,  0,  3],\n",
       "       [14, 29,  0,  2],\n",
       "       [23, 36,  1,  2],\n",
       "       [45, 47,  1,  2],\n",
       "       [40, 42,  1,  2],\n",
       "       [ 4, 46,  1,  2],\n",
       "       [ 5, 15,  1,  2],\n",
       "       [11, 12,  1,  2],\n",
       "       [43, 44,  1,  2],\n",
       "       [49, 62,  1,  3],\n",
       "       [48, 54,  1,  3],\n",
       "       [39, 56,  1,  4],\n",
       "       [ 0, 52,  1,  5],\n",
       "       [19, 71,  1,  3],\n",
       "       [63, 67,  1,  4],\n",
       "       [59, 70,  1,  4],\n",
       "       [58, 68,  1,  5],\n",
       "       [66, 73,  1,  5],\n",
       "       [64, 80,  1,  6],\n",
       "       [61, 72,  1,  6],\n",
       "       [74, 78,  2,  7],\n",
       "       [76, 83,  2,  8],\n",
       "       [77, 81,  2,  8],\n",
       "       [75, 84,  2,  9],\n",
       "       [69, 82,  2,  7],\n",
       "       [79, 86,  3, 10],\n",
       "       [33, 85,  3,  7],\n",
       "       [ 3, 88,  3,  9],\n",
       "       [90, 93,  3, 16],\n",
       "       [87, 89,  5, 17],\n",
       "       [91, 92,  5, 17],\n",
       "       [95, 96, 37, 34],\n",
       "       [94, 97, 64, 50]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc8943",
   "metadata": {},
   "source": [
    "# üìå Approach 2: Divisive Clustering (Top-Down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6976",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb97a5f",
   "metadata": {},
   "source": [
    "**Hierarchical Clustering** is a clustering technique that builds nested groups of data points, forming a hierarchy. It doesn‚Äôt involve trees like decision trees; instead, it constructs a dendrogram, which is a tree-like diagram used to visualize how individual data points or smaller clusters are merged together step by step based on a distance metric.\n",
    "\n",
    "**There are two main types of hierarchical clustering:**\n",
    "\n",
    "**Agglomerative (Bottom-Up):** Starts with each data point as its own cluster and gradually merges the closest pairs of clusters.\n",
    "\n",
    "**Divisive (Top-Down):** Starts with all data points in one cluster and splits them into smaller clusters recursively.\n",
    "\n",
    "The output is a hierarchy of clusters ‚Äî not a model with decision rules ‚Äî and it's especially useful when you want to understand the data structure or determine the number of natural groupings without predefining it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60772b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
